{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chien-noir/AMLS_22-23_SN18001485/blob/main/ResNet_modified.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiflCH5wZ41J"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bguBbLcKGG7x"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import PIL\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense,BatchNormalization,MaxPooling2D,Conv2D,ZeroPadding2D,Activation,AveragePooling2D, Flatten \n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import cv2\n",
        "import dlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg5gnwdSP7Ek"
      },
      "source": [
        "# **Get labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JLtSJw_PsMB"
      },
      "outputs": [],
      "source": [
        "# PATH TO ALL IMAGES\n",
        "\n",
        "basedir = '/content/drive/MyDrive/Colab Notebooks/dataset_AMLS_22-23'\n",
        "images_dir = os.path.join(basedir,'cartoon_set')\n",
        "images_dir = os.path.join(images_dir,'img')\n",
        "labels_filename = 'labels.csv'\n",
        "\n",
        "#image path and read and open all images\n",
        "\n",
        "image_paths = [os.path.join(images_dir, l) for l in os.listdir(images_dir)]\n",
        "target_size = None\n",
        "labels_file = open(os.path.join('/content/drive/MyDrive/Colab Notebooks/dataset_AMLS_22-23/cartoon_set', labels_filename), 'r')\n",
        "lines = labels_file.readlines()\n",
        "\n",
        "#set the switch for accessing the label\n",
        "eye_color= 1\n",
        "face_shape = 2\n",
        "\n",
        "labels = [int(line.split('\\t')[face_shape]) for line in lines[1:]]\n",
        "print(labels)\n",
        "if os.path.isdir(images_dir):\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "    for img_path in image_paths:\n",
        "        file_name= img_path.split('.')[0].split('/')[-1]\n",
        "        file_name = int(file_name)\n",
        "        all_labels.append(labels[file_name])\n",
        "\n",
        "labels = np.array(all_labels)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iTN0l-NWTvh"
      },
      "source": [
        "# **Get graph data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FP0tQ_cWcfz"
      },
      "outputs": [],
      "source": [
        "target_size = (100, 100) #grpah target size\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/dataset_AMLS_22-23/cartoon_set/img'\n",
        "filename = os.listdir(path)\n",
        "input = []  #create an empty array\n",
        "label_set = []\n",
        "counter = 0\n",
        "counting = 0\n",
        "num_limit = 2000\n",
        "\n",
        "image_data = []  #create a array for sotring the data \n",
        "for file in filename:\n",
        "  counter = counter + 1\n",
        "  counting = counting +1\n",
        "  inputImg = PIL.Image.open(os.path.join(path,file)).convert('RGB')\n",
        "  name_label = int((os.path.join(path,file)).split('.')[0].split('/')[-1])\n",
        "  label = labels[name_label]\n",
        "  label_set.append(labels[label])\n",
        "  input_array= np.asarray(inputImg)\n",
        "\n",
        "  #resize the arraty to have lower resulution, which is set by traget size\n",
        "  input_array= cv2.resize(input_array,target_size)\n",
        "  input.append(input_array)\n",
        "  #print the process\n",
        "  if counter %100 ==0:\n",
        "    print('process:',counter)\n",
        "\n",
        "  #break when the data reach the limitation\n",
        "  if counting == num_limit:\n",
        "    break\n",
        "\n",
        "spl = int(0.8*num_limit)\n",
        "train_input = input[:spl]\n",
        "test_input = input[spl:]\n",
        "train_label = label_set[:spl]\n",
        "test_label = label_set[spl:]\n",
        "input_tensor = tf.convert_to_tensor(train_input)               \n",
        "input = np.array(input.append(input_array))\n",
        "label_set = label_set\n",
        "##convert the array into the tensor\n",
        "#input_tensor = tf.convert_to_tensor(input)\n",
        "label_tensor= tf.convert_to_tensor(train_label)\n",
        "\n",
        "test_input_tensor = tf.convert_to_tensor(test_input)  \n",
        "test_label_tensor= tf.convert_to_tensor(test_label)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for element in input_tensor:\n",
        "  print(element)"
      ],
      "metadata": {
        "id": "_pBPlwXM44c6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mjMMyedaPNX"
      },
      "source": [
        "# **Test if the graph has been extracted**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5B3Z98UaNEz"
      },
      "outputs": [],
      "source": [
        "print(label_set)\n",
        "print(input)\n",
        "print('shape of the array',input.size)\n",
        "for element in input_tensor:\n",
        "  print(element)\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVa-MFyTWdrP"
      },
      "source": [
        "this is the code for getting the data refered from online"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wq1QtgHGM3i"
      },
      "outputs": [],
      "source": [
        "#img_path = glob.glob('foods/train/*/*.jpg')\n",
        "img_path = glob.glob('/content/drive/MyDrive/Colab Notebooks/dataset_AMLS_22-23/cartoon_set/img1/*.png')\n",
        "print(img_path)\n",
        "#labels = [img.split('/')[8] for img in img_path]\n",
        "#labels = [img.split('/')[8].split('.')[0] for img in img_path]\n",
        "# label = np.unique(labels)\n",
        "print(labels)\n",
        "print(label)\n",
        "# label_to_index = dict((item, index) for (index, item) in enumerate(label))\n",
        "# index_to_label = dict((index, item) for (item, index) in label_to_index.items())\n",
        " \n",
        "# index_labels = [label_to_index.get(name) for name in labels] # 映射\n",
        "# print(index_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvkiSXWbGOWZ"
      },
      "outputs": [],
      "source": [
        "#index_labels[:3] # index_labels为标签数组"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-20RtcsGGPAz"
      },
      "outputs": [],
      "source": [
        "random_index = np.random.permutation(len(img_path))\n",
        " \n",
        "img_path = np.array(img_path)[random_index]\n",
        "label_set = np.array(label_set)[random_index]\n",
        "# print(train_img_path)\n",
        "divider = int(len(img_path) * 0.8)\n",
        "# print(divider)\n",
        "train_path = img_path[:divider]\n",
        "train_label = label_set[:divider]\n",
        "test_path = img_path[divider:]\n",
        "test_label = label_set[divider:]\n",
        "# print(train_label)\n",
        "# print(train_path)\n",
        "# print(test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNPyv9ZkI2dK"
      },
      "outputs": [],
      "source": [
        "# 数据集\n",
        "# print(train_path)\n",
        "\n",
        "train_datasets = tf.data.Dataset.from_tensor_slices((train_path, train_label))\n",
        "\n",
        "for element in train_datasets:\n",
        "  print(element)\n",
        "test_datasets = tf.data.Dataset.from_tensor_slices((test_path, test_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUDvbwr9GRK7"
      },
      "outputs": [],
      "source": [
        "def load_img(img_path, img_label):\n",
        "    image = tf.io.read_file(img_path)\n",
        "    image = tf.image.decode_png(image, channels = 3, dtype=tf.dtypes.uint8) # 将image解码，通道数为3\n",
        "    #image = tf.image.decode_jpeg(image, channels = 3) # 将image解码，通道数为3\n",
        "    image = tf.image.resize(image, [224, 224])\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = image / 255 # 归一化\n",
        "    return image, img_label\n",
        "img11, img_label11 = load_img(train_path[1], train_label[1])\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE # 多线程\n",
        "train_datasets = train_datasets.map(load_img, num_parallel_calls=AUTOTUNE)\n",
        "test_datasets = test_datasets.map(load_img, num_parallel_calls=AUTOTUNE)\n",
        "BATCH_SIZE = 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(img11)\n",
        "print(img_label11)\n"
      ],
      "metadata": {
        "id": "cA3r3VjWjoDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lthz-BBeGSmx"
      },
      "outputs": [],
      "source": [
        "train_datasets = train_datasets.repeat().shuffle(300).batch(BATCH_SIZE)\n",
        "# <BatchDataset shapes: ((None, 224, 224, 3), (None,)), types: (tf.float32, tf.int64)>\n",
        "#print(train_datasets.size)\n",
        "test_datasets = test_datasets.batch(BATCH_SIZE)\n",
        "\n",
        "# <BatchDataset shapes: ((None, 224, 224, 3), (None,)), types: (tf.float32, tf.int64)>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***The code template for residual unit***"
      ],
      "metadata": {
        "id": "kZZeLK-RoSYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "def residual_unit(img_data, channel_of_filter, strides=(2, 2)):\n",
        " \n",
        "    channel1, channel2, channel3 = channel_of_filter\n",
        "    #bottelneck\n",
        "\n",
        "    # the first 1*1 conv\n",
        "    x = Conv2D(channel1, (1, 1), strides=strides,)(img_data)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.2)(x) # dropout\n",
        "    x = Activation('relu')(x)\n",
        " \n",
        "    #the middle 3*3 conv  \n",
        "    x = Conv2D(channel2, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Activation('relu')(x)\n",
        " \n",
        "    # the last 1*1 conv\n",
        "    x = Conv2D(channel3, (1, 1))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.2)(x) # dropout\n",
        " \n",
        "    # shortcur settings\n",
        "    shortcut = Conv2D(channel3, (1, 1), strides=strides)(img_data)\n",
        "    shortcut = BatchNormalization()(shortcut)\n",
        "    x = layers.add([x, shortcut])  #'add' algorithm\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "\n",
        "    return x\n",
        "\n",
        "def residual_unit2(img_data, channel_of_filter, strides=(2, 2)):\n",
        " \n",
        "    channel1, channel2, channel3 = channel_of_filter\n",
        "    #bottelneck\n",
        "\n",
        "    # the first 1*1 conv\n",
        "    x = Conv2D(channel1, (1, 1), strides=strides,)(img_data)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.2)(x) # dropout\n",
        "    x = Activation('relu')(x)\n",
        " \n",
        "    #the middle 3*3 conv  \n",
        "    x = Conv2D(channel2, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Activation('relu')(x)\n",
        " \n",
        "    # the last 1*1 conv\n",
        "    x = Conv2D(channel3, (1, 1))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.2)(x) # dropout\n",
        " \n",
        "    \n",
        "    x = layers.add([x, img_data])  #'add' algorithm\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "\n",
        "    return x\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NBQo7OR5oeIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***code higgen***"
      ],
      "metadata": {
        "id": "3iDBq8AiqXrX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SyE9hYIGTyo"
      },
      "outputs": [],
      "source": [
        " \n",
        "def conv_block(img_data, kernel_size, filters, stage, block, strides=(2, 2)):\n",
        " \n",
        "    # 64,64,256\n",
        "    filters1, filters2, filters3 = filters\n",
        " \n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        " \n",
        "    # the first 1*1 conv\n",
        "    x = Conv2D(filters1, (1, 1), strides=strides,\n",
        "               name=conv_name_base + '2a')(img_data)\n",
        "    x = BatchNormalization(name=bn_name_base + '2a')(x)\n",
        "    x = Dropout(0.2)(x) # dropout\n",
        "    x = Activation('relu')(x)\n",
        " \n",
        "    # \n",
        "    x = Conv2D(filters2, kernel_size, padding='same',\n",
        "               name=conv_name_base + '2b')(x)\n",
        "    x = BatchNormalization(name=bn_name_base + '2b')(x)\n",
        "    \n",
        "    # dropout\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Activation('relu')(x)\n",
        " \n",
        "    # 升维\n",
        "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
        "    x = BatchNormalization(name=bn_name_base + '2c')(x)\n",
        "    x = Dropout(0.2)(x) # dropout\n",
        " \n",
        "    # 残差边\n",
        "    shortcut = Conv2D(filters3, (1, 1), strides=strides, name=conv_name_base + '1')(img_data) # 将input_tensor转换为对应维度（w x h x c）\n",
        "    shortcut = BatchNormalization(name=bn_name_base + '1')(shortcut)\n",
        " \n",
        " \n",
        "    x = layers.add([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLvUIpQPGUSS"
      },
      "outputs": [],
      "source": [
        "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        " \n",
        "    [filters1, filters2, filters3] = filters\n",
        "    # filters = [512, 512, 1024]\n",
        "    # filters1 = 512, filters2 = 512, filters3 = 1024\n",
        "    # print(filters1)\n",
        "    # print(filters)\n",
        " \n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        " \n",
        "    # 降维\n",
        "    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
        "    x = BatchNormalization(name=bn_name_base + '2a')(x)\n",
        "    x = Dropout(0.2)(x) # dropout\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    \n",
        "    # 3x3卷积\n",
        "    x = Conv2D(filters2, kernel_size,padding='same', name=conv_name_base + '2b')(x)\n",
        "    \n",
        "    x = Dropout(0.2)(x) # dropout\n",
        "    \n",
        "    x = BatchNormalization(name=bn_name_base + '2b')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    \n",
        "    # 升维\n",
        "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
        "    x = BatchNormalization(name=bn_name_base + '2c')(x)\n",
        "    x = Dropout(0.2)(x) # dropout\n",
        " \n",
        "    x = layers.add([x, input_tensor])\n",
        "    x = Activation('relu')(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***MODIFIED SHAPE DATA FOR THE RESNET*** \n"
      ],
      "metadata": {
        "id": "wbLbphRaSymQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(img_data, kernel_size, filters, stage, block, strides=(2, 2)):\n",
        " \n",
        "    # 64,64,256\n",
        "    filters1, filters2, filters3 = filters\n",
        " \n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        " \n",
        "    # the first 1*1 conv\n",
        "    x = Conv2D(filters1, (1, 1), strides=strides,\n",
        "               name=conv_name_base + '2a')(img_data)\n",
        "    x = BatchNormalization(name=bn_name_base + '2a')(x)\n",
        "    x = Dropout(0.2)(x) # dropout\n",
        "    x = Activation('relu')(x)\n",
        " \n",
        "    # \n",
        "    x = Conv2D(filters2, kernel_size, padding='same',\n",
        "               name=conv_name_base + '2b')(x)\n",
        "    x = BatchNormalization(name=bn_name_base + '2b')(x)\n",
        "    \n",
        "    # dropout\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Activation('relu')(x)\n",
        " \n",
        "    # 升维\n",
        "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
        "    x = BatchNormalization(name=bn_name_base + '2c')(x)\n",
        "    x = Dropout(0.2)(x) # dropout\n",
        " \n",
        "    # 残差边\n",
        "    shortcut = Conv2D(filters3, (1, 1), strides=strides, name=conv_name_base + '1')(img_data) # 将input_tensor转换为对应维度（w x h x c）\n",
        "    shortcut = BatchNormalization(name=bn_name_base + '1')(shortcut)\n",
        " \n",
        " \n",
        "    x = layers.add([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        " \n",
        "    [filters1, filters2, filters3] = filters\n",
        "    # filters = [512, 512, 1024]\n",
        "    # filters1 = 512, filters2 = 512, filters3 = 1024\n",
        "    # print(filters1)\n",
        "    # print(filters)\n",
        " \n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        " \n",
        "    # 降维\n",
        "    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
        "    x = BatchNormalization(name=bn_name_base + '2a')(x)\n",
        "    x = Dropout(0.2)(x) # dropout\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    \n",
        "    # 3x3卷积\n",
        "    x = Conv2D(filters2, kernel_size,padding='same', name=conv_name_base + '2b')(x)\n",
        "    \n",
        "    x = Dropout(0.2)(x) # dropout\n",
        "    \n",
        "    x = BatchNormalization(name=bn_name_base + '2b')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    \n",
        "    # 升维\n",
        "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
        "    x = BatchNormalization(name=bn_name_base + '2c')(x)\n",
        "    x = Dropout(0.2)(x) # dropout\n",
        " \n",
        "    x = layers.add([x, input_tensor])\n",
        "    x = Activation('relu')(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "2mCI0iHBTAk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The code template for Resnet50**"
      ],
      "metadata": {
        "id": "u8W7Jtqitorj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet50(img_size=[224,224,3],classes=5):\n",
        "\n",
        "    img_input = tf.keras.layers.Input(shape=img_size)\n",
        "    x = ZeroPadding2D((3, 3))(img_input)   \n",
        "\n",
        "    #stage 1\n",
        "    x = Conv2D(64, (7, 7), strides=(2, 2))(x)  \n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        " \n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2))(x) \n",
        "    \n",
        "    #[filter1, filter2 , filter3]=[64, 64, 256]\n",
        " \n",
        "    # stage 2\n",
        "    x = residual_unit(x, [64, 64, 256], strides=(1, 1))\n",
        "    x = residual_unit2(x,  [64, 64, 256])\n",
        "    x = residual_unit2(x,  [64, 64, 256])\n",
        " \n",
        "    # stage 3\n",
        "    x = residual_unit(x, [128, 128, 512])\n",
        "    x = residual_unit2(x, [128, 128, 512])\n",
        "    x = residual_unit2(x, [128, 128, 512])\n",
        "    x = residual_unit2(x, [128, 128, 512])\n",
        " \n",
        "    # stage 4\n",
        "    x = residual_unit(x, [256, 256, 1024])\n",
        "    x = residual_unit2(x, [256, 256, 1024])\n",
        "    x = residual_unit2(x, [256, 256, 1024])\n",
        "    x = residual_unit2(x, [256, 256, 1024])\n",
        "    x = residual_unit2(x, [256, 256, 1024])\n",
        "    x = residual_unit2(x, [256, 256, 1024])\n",
        "   \n",
        " \n",
        "    # stage 5\n",
        "    x = residual_unit(x, [512, 512, 2048])\n",
        "    x = residual_unit2(x, [512, 512, 2048])\n",
        "    x = residual_unit2(x, [512, 512, 2048])\n",
        " \n",
        "    # the last layer\n",
        "    x = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(classes, activation='softmax', name='fc5')(x)\n",
        "\n",
        "    #create the model\n",
        "    model = Model(img_input, x, name='resnet50')\n",
        " \n",
        "    return model"
      ],
      "metadata": {
        "id": "3Nf7A2adtoMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***The real code for the module ***"
      ],
      "metadata": {
        "id": "z6X_8zpUyjDB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npwWxnuZGXdD"
      },
      "outputs": [],
      "source": [
        "\n",
        "def ResNet50(input_shape=[224,224,3],classes=5):\n",
        "    # [224,224,3]\n",
        "    img_input = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = ZeroPadding2D((3, 3))(img_input)   # [230,230,3]\n",
        "    # [112,112,64]\n",
        "\n",
        "\n",
        "    #15*15\n",
        "    #filter, under this condtion, is the cahnnel number \n",
        "    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)   #[112,112,64]   [15 15 64]\n",
        "    x = BatchNormalization(name='bn_conv1')(x)\n",
        "    x = Activation('relu')(x)\n",
        " \n",
        "    # [56,56,64]   [48 48 64]\n",
        "    #x = MaxPooling2D((3, 3), strides=(2, 2))(x)  #channel 128\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2))(x)  #channel 128\n",
        " \n",
        "    # [56,56,256]\n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
        " \n",
        "    # [28,28,512]\n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
        " \n",
        "    # [14,14,1024]\n",
        "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
        "   \n",
        " \n",
        "    # [7,7,2048]\n",
        "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
        " \n",
        "    # 代替全连接层\n",
        "    x = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
        " \n",
        "    # 进行预测\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(classes, activation='softmax', name='fc5')(x)\n",
        " \n",
        "    model = Model(img_input, x, name='resnet50')\n",
        " \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***MODIFIED MDOEL FOR DIFERENT SHAPE OF THE INPUT*** \n"
      ],
      "metadata": {
        "id": "uirmwJJAfHt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet50(input_shape=[100 , 100 ,3],classes=5):\n",
        "    # [224,224,3]\n",
        "    img_input = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = ZeroPadding2D((3 , 3))(img_input)   # [230,230,3]\n",
        "    # [112,112,64]\n",
        "\n",
        "\n",
        "    #15*15\n",
        "    #filter, under this condtion, is the cahnnel number \n",
        "    x = Conv2D(64, (2 , 2 ), strides=(2, 2), name='conv1')(x)   #[112,112,64]   [15 15 64]\n",
        "    x = BatchNormalization(name='bn_conv1')(x)\n",
        "    x = Activation('relu')(x)\n",
        " \n",
        "    # [56,56,64]   [48 48 64]\n",
        "    #x = MaxPooling2D((3, 3), strides=(2, 2))(x)  #channel 128\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2))(x)  #channel 128\n",
        " \n",
        "    # [56,56,256]\n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
        " \n",
        "    # [28,28,512]\n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
        " \n",
        "    # [14,14,1024]\n",
        "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
        "   \n",
        " \n",
        "    # [7,7,2048]\n",
        "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
        " \n",
        "    # 代替全连接层\n",
        "    x = AveragePooling2D((3 , 3), name='avg_pool')(x)\n",
        " \n",
        "    # 进行预测\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(classes, activation='softmax', name='fc5')(x)\n",
        " \n",
        "    model = Model(img_input, x, name='resnet50')\n",
        " \n",
        "    return model"
      ],
      "metadata": {
        "id": "hrH4OhptfOsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Use this one with different shape***"
      ],
      "metadata": {
        "id": "AbqoD8QP1Vp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# resnet18： ResNet(BasicBlock, [2, 2, 2, 2])\n",
        " \n",
        "# resnet34： ResNet(BasicBlock, [3, 4, 6, 3])\n",
        " \n",
        "# resnet50：ResNet(Bottleneck, [3, 4, 6, 3])\n",
        " \n",
        "# resnet101:ResNet(Bottleneck, [3, 4, 23, 3])\n",
        " \n",
        "# resnet152:ResNet(Bottleneck, [3, 8, 36, 3])\n",
        " \n",
        "def ResNet50(input_shape=[30, 30 ,3],classes=5):\n",
        "    # [224,224,3]\n",
        "    img_input = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = ZeroPadding2D((3, 3))(img_input)   # [230,230,3]\n",
        "    # [112,112,64]\n",
        "    #filter, under this condtion, is the cahnnel number \n",
        "    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)   #[112,112,64]\n",
        "    x = BatchNormalization(name='bn_conv1')(x)\n",
        "    x = Activation('relu')(x)\n",
        " \n",
        "    # [56,56,64]\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        " \n",
        "    # [56,56,256]\n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
        " \n",
        "    # [28,28,512]\n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
        " \n",
        "    # [14,14,1024]\n",
        "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
        "   \n",
        " \n",
        "    # [7,7,2048]\n",
        "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
        " \n",
        "    # 代替全连接层\n",
        "    x = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
        " \n",
        "    # 进行预测\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(classes, activation='softmax', name='fc5')(x)\n",
        " \n",
        "    model = Model(img_input, x, name='resnet50')\n",
        " \n",
        "    return model"
      ],
      "metadata": {
        "id": "6WawKUIw1Uio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "hide the code\n",
        "# ***New section***\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "bV1kLzpW7rGT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78nMdewCGZD4"
      },
      "outputs": [],
      "source": [
        "def ResNet101(input_shape=[224,224,3],classes=5):\n",
        "    # [224,224,3]\n",
        "    img_input = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = ZeroPadding2D((3, 3))(img_input)   # [230,230,3]\n",
        "    # [112,112,64]\n",
        "    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)   #[112,112,64]\n",
        "    x = BatchNormalization(name='bn_conv1')(x)\n",
        "    x = Activation('relu')(x)\n",
        " \n",
        "    # [56,56,64]\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        " \n",
        "    # [56,56,256]\n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
        " \n",
        "    # [28,28,512]\n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
        " \n",
        "    # [14,14,1024]\n",
        "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='g')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='h')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='i')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='j')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='k')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='l')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='m')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='n')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='o')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='p')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='q')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='r')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='s')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='t')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='u')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='v')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='w')\n",
        " \n",
        "    # [7,7,2048]\n",
        "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
        " \n",
        "    # 代替全连接层\n",
        "    x = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
        " \n",
        "    # 分类预测\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(classes, activation='softmax', name='fc5')(x)\n",
        " \n",
        "    model = Model(img_input, x, name='resnet101')\n",
        " \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Block***"
      ],
      "metadata": {
        "id": "EVuLH9jVsWbN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLO4M6YRGcmE"
      },
      "outputs": [],
      "source": [
        "# model = ResNet50(input_shape=[224,224,3],classes=5)\n",
        "model = ResNet50()\n",
        "#model = ResNet101()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIF34VXyGhp0"
      },
      "outputs": [],
      "source": [
        "sgd = tf.keras.optimizers.SGD(lr=0.01, momentum=0.8, decay=0.0, nesterov=False)\n",
        "BATCH_SIZE = 100\n",
        "model.compile(optimizer=sgd,\n",
        "             #loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "             loss = 'sparse_categorical_crossentropy', #交叉熵损失\n",
        "             metrics=['accuracy']\n",
        "             )\n",
        " \n",
        "# train_count = len(train_path)\n",
        "# test_count = len(test_path)\n",
        " \n",
        "steps_per_epoch = spl // BATCH_SIZE\n",
        "validation_steps = (num_limit-spl) // BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hvVzxGIGiuY"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        " \n",
        "early_stopping = EarlyStopping(\n",
        "    min_delta=0.0008, # minimium amount of change to count as an improvement\n",
        "    patience=40, # how many epochs to wait before stopping\n",
        "    restore_best_weights=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.run_functions_eagerly(True)"
      ],
      "metadata": {
        "id": "i4sM8BbjUrHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTjBMexRGkKB"
      },
      "outputs": [],
      "source": [
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "\n",
        "# 开始训\n",
        "# for element in test_datasets:\n",
        "#   #print(element)\n",
        "#   history = model.fit(\n",
        "#                     input_tensor, label_tensor,\n",
        "#                     epochs = 120,\n",
        "#                     steps_per_epoch = steps_per_epoch,\n",
        "#                     validation_data = test_datasets,\n",
        "#                     validation_steps = validation_steps,\n",
        "#                     callbacks=[early_stopping], # put your callbacks in a list\n",
        "#                     )\n",
        "history = model.fit(input_tensor, label_tensor,\n",
        "                    epochs = 10 ,\n",
        "                    steps_per_epoch = steps_per_epoch,\n",
        "                    validation_data = (test_input_tensor,test_label_tensor),\n",
        "                    validation_steps = validation_steps,\n",
        "                    callbacks=[early_stopping], # put your callbacks in a list\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUizav2OGlxL"
      },
      "outputs": [],
      "source": [
        "#model.save('myModel.h5')\n",
        "\n",
        "history.history.keys()\n",
        "# dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrUsJAo8GnGI"
      },
      "outputs": [],
      "source": [
        "# 画出精确值变化图像\n",
        "plt.plot(history.epoch, history.history.get('accuracy'), label='accuracy')\n",
        "plt.plot(history.epoch, history.history.get('val_accuracy'), label='val_accuracy')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55eTw9GKGpMM"
      },
      "outputs": [],
      "source": [
        "# 画出损失值变化图像\n",
        "plt.plot(history.epoch, history.history.get('loss'), label='loss')\n",
        "plt.plot(history.epoch, history.history.get('val_loss'), label='val_loss')\n",
        "plt.legend()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "3mjMMyedaPNX",
        "AbqoD8QP1Vp0"
      ],
      "authorship_tag": "ABX9TyMeRHiGiOF9hvRtzJ1jlP6X",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}